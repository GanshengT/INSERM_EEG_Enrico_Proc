{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ASR Algo without understanding principles\n",
    "* not a automated process - test on subj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file /home/gansheng.tan/process_mne/INSERM_EEG_Enrico_Proc/data_eeglab/filt_data/subj094_FA1_filt_raw.fif...\n",
      "    Range : 0 ... 294399 =      0.000 ...   574.998 secs\n",
      "Ready.\n",
      "Reading 0 ... 294399  =      0.000 ...   574.998 secs...\n",
      "Creating RawArray with float64 data, n_channels=1, n_times=15361\n",
      "    Range : 0 ... 15360 =      0.000 ...    30.000 secs\n",
      "Ready.\n",
      "Determining time window rejection thresholds...\n",
      "for each channel...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-10789afcdf17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mYule_Walker_filtering\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_asrcalibration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_asrcalibration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawCalibAsr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mChanName4VEOG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYule_Walker_filtering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/process_mne/INSERM_EEG_Enrico_Proc/utils_prep/preproc_manu/ASR/util/raw_asrcalibration.py\u001b[0m in \u001b[0;36mraw_asrcalibration\u001b[0;34m(raw, ChanName4VEOG, cutoff, Yule_Walker_filtering)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mref_wndlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mSignalClean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_windows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSignalCalib\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sfreq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mref_maxbadchannels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mref_tolerances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mref_wndlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0msrate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sfreq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/process_mne/INSERM_EEG_Enrico_Proc/utils_prep/preproc_manu/ASR/util/asr.py\u001b[0m in \u001b[0;36mclean_windows\u001b[0;34m(Signal, srate, max_bad_channels, zthresholds, window_len)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_eeg_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_clean_fraction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_dropout_fraction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtruncate_quant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_sizes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0michan\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m            \u001b[0mwz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/process_mne/INSERM_EEG_Enrico_Proc/utils_prep/preproc_manu/ASR/util/tools.py\u001b[0m in \u001b[0;36mfit_eeg_distribution\u001b[0;34m(X, min_clean_fraction, max_dropout_fraction, quants, step_sizes, beta)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mnewX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miX\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrowval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0mX1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0mnewX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewX\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Modified on July 2\n",
    "\n",
    "@author: Manu, Gansheng\n",
    "\"\"\"\n",
    "\n",
    "import mne\n",
    "from mne import io\n",
    "import sys\n",
    "sys.path.append('/home/gansheng.tan/process_mne/INSERM_EEG_Enrico_Proc/utils_prep/preproc_manu/ASR/')\n",
    "import scipy\n",
    "import numpy as np\n",
    "from util import tools,asr,raw_asrcalibration\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.viz import plot_evoked_topo\n",
    "\n",
    "\n",
    "#### import filt data #####\n",
    "\n",
    "filt_data_path = '/home/gansheng.tan/process_mne/INSERM_EEG_Enrico_Proc/data_eeglab/filt_data/'\n",
    "subj = '94'\n",
    "state = 'FA1'\n",
    "raw_filt_fname = filt_data_path + 'subj0'+str(subj)+'_'+state+'_filt_raw.fif'\n",
    "raw_filt = io.read_raw_fif(raw_filt_fname,preload=True)\n",
    "# picks=mne.pick_channels(raw_filt.info,eeg=True)\n",
    "raw_filt.pick_types(eeg=True)\n",
    "\n",
    "############### begin ASR process\n",
    "rawCalibAsr=raw_filt.copy()\n",
    "tmin = 30\n",
    "tmax = 60 #s\n",
    "rawCalibAsr = rawCalibAsr.crop(tmin=tmin,tmax=tmax)\n",
    "\n",
    "ChanName4VEOG = ['Fp1','Fp2'] # 2 VEOG\n",
    "cutoff = 5\n",
    "\n",
    "Yule_Walker_filtering = True\n",
    "state = raw_asrcalibration.raw_asrcalibration(rawCalibAsr,ChanName4VEOG, cutoff,Yule_Walker_filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fp1',\n",
       " 'AF7',\n",
       " 'AF3',\n",
       " 'F1',\n",
       " 'F3',\n",
       " 'F5',\n",
       " 'F7',\n",
       " 'FT7',\n",
       " 'FC5',\n",
       " 'FC3',\n",
       " 'FC1',\n",
       " 'C1',\n",
       " 'C3',\n",
       " 'C5',\n",
       " 'T7',\n",
       " 'TP7',\n",
       " 'CP5',\n",
       " 'CP3',\n",
       " 'CP1',\n",
       " 'P1',\n",
       " 'P3',\n",
       " 'P5',\n",
       " 'P7',\n",
       " 'P9',\n",
       " 'PO7',\n",
       " 'PO3',\n",
       " 'O1',\n",
       " 'Iz',\n",
       " 'Oz',\n",
       " 'POz',\n",
       " 'CPz',\n",
       " 'Fpz',\n",
       " 'Fp2',\n",
       " 'AF8',\n",
       " 'AF4',\n",
       " 'AFz',\n",
       " 'Fz',\n",
       " 'F2',\n",
       " 'F4',\n",
       " 'F6',\n",
       " 'F8',\n",
       " 'FT8',\n",
       " 'FC6',\n",
       " 'FC4',\n",
       " 'FC2',\n",
       " 'FCz',\n",
       " 'Cz',\n",
       " 'C2',\n",
       " 'C4',\n",
       " 'C6',\n",
       " 'T8',\n",
       " 'TP8',\n",
       " 'CP6',\n",
       " 'CP4',\n",
       " 'CP2',\n",
       " 'P2',\n",
       " 'P4',\n",
       " 'P6',\n",
       " 'P8',\n",
       " 'P10',\n",
       " 'PO8',\n",
       " 'PO4',\n",
       " 'O2']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_filt.ch_names\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file /home/gansheng.tan/process_mne/INSERM_EEG_Enrico_Proc/data_eeglab/filt_data/subj094_FA1_filt_raw.fif...\n",
      "    Range : 0 ... 294399 =      0.000 ...   574.998 secs\n",
      "Ready.\n",
      "Reading 0 ... 294399  =      0.000 ...   574.998 secs...\n",
      "-512 174.0\n",
      "Determining time window rejection thresholds...\n",
      "for each channel...\n",
      "C is 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gansheng.tan/mne/local/lib/python3.5/site-packages/ipykernel_launcher.py:282: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/home/gansheng.tan/mne/local/lib/python3.5/site-packages/ipykernel_launcher.py:283: RuntimeWarning: invalid value encountered in multiply\n",
      "/home/gansheng.tan/mne/local/lib/python3.5/site-packages/ipykernel_launcher.py:282: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/gansheng.tan/mne/local/lib/python3.5/site-packages/ipykernel_launcher.py:302: RuntimeWarning: divide by zero encountered in log\n",
      "/home/gansheng.tan/mne/local/lib/python3.5/site-packages/ipykernel_launcher.py:597: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/gansheng.tan/mne/local/lib/python3.5/site-packages/ipykernel_launcher.py:599: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/gansheng.tan/mne/local/lib/python3.5/site-packages/ipykernel_launcher.py:606: RuntimeWarning: invalid value encountered in greater\n",
      "/home/gansheng.tan/mne/local/lib/python3.5/site-packages/ipykernel_launcher.py:609: RuntimeWarning: invalid value encountered in less\n",
      "/home/gansheng.tan/mne/local/lib/python3.5/site-packages/ipykernel_launcher.py:623: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-57037636e3a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mYule_Walker_filtering\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_asrcalibration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawCalibAsr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mChanName4VEOG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYule_Walker_filtering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-59-265b557563e5>\u001b[0m in \u001b[0;36mraw_asrcalibration\u001b[0;34m(raw, ChanName4VEOG, cutoff, Yule_Walker_filtering)\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0mref_wndlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m     \u001b[0mSignalClean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_windows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSignalCalib\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sfreq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mref_maxbadchannels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mref_tolerances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mref_wndlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m     \u001b[0msrate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sfreq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-265b557563e5>\u001b[0m in \u001b[0;36mclean_windows\u001b[0;34m(Signal, srate, max_bad_channels, zthresholds, window_len)\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0msample_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;31m######################### modification add int########################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m     \u001b[0msample_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_mask2remove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mSignalClean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Modified on July 2\n",
    "\n",
    "@author: Manu, Gansheng\n",
    "\"\"\"\n",
    "\n",
    "import mne\n",
    "from mne import io\n",
    "import sys\n",
    "sys.path.append('C:/_MANU/_U821/Python_Dev/')\n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.viz import plot_evoked_topo\n",
    "\n",
    "\n",
    "#### import filt data #####\n",
    "\n",
    "filt_data_path = '/home/gansheng.tan/process_mne/INSERM_EEG_Enrico_Proc/data_eeglab/filt_data/'\n",
    "subj = '94'\n",
    "state = 'FA1'\n",
    "raw_filt_fname = filt_data_path + 'subj0'+str(subj)+'_'+state+'_filt_raw.fif'\n",
    "raw_filt = io.read_raw_fif(raw_filt_fname,preload=True)\n",
    "\n",
    "################ begin ASR process\n",
    "rawCalibAsr=raw_filt.copy()\n",
    "tmin = 30\n",
    "tmax = 60 #s\n",
    "rawCalibAsr = rawCalibAsr.crop(tmin=tmin,tmax=tmax)\n",
    "\n",
    "ChanName4VEOG = ['VEOG'] # 2 VEOG\n",
    "cutoff = 5\n",
    "\n",
    "Yule_Walker_filtering = True\n",
    "state = raw_asrcalibration(rawCalibAsr,ChanName4VEOG, cutoff,Yule_Walker_filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import toeplitz\n",
    "from scipy import signal\n",
    "from numpy import linalg\n",
    "import numpy.matlib\n",
    "from mne.preprocessing import peak_finder\n",
    "\n",
    "def polystab(a):\n",
    "    #POLYSTAB Polynomial stabilization.\n",
    "    #   POLYSTAB(A), where A is a vector of polynomial coefficients,\n",
    "    #   stabilizes the polynomial with respect to the unit circle;\n",
    "    #   roots whose magnitudes are greater than one are reflected\n",
    "    #   inside the unit circle.\n",
    "    #\n",
    "    #   # Example:\n",
    "    #   #   Convert a linear-phase filter into a minimum-phase filter with the \n",
    "    #   #   same magnitude response.\n",
    "    #\n",
    "    #   h = fir1(25,0.4);               # Window-based FIR filter design\n",
    "    #   flag_linphase = islinphase(h)   # Determines if filter is linear phase\n",
    "    #   hmin = polystab(h) * norm(h)/norm(polystab(h)); \n",
    "    #   flag_minphase = isminphase(hmin)# Determines if filter is minimum phase\n",
    "    \n",
    "    v = np.roots(a);\n",
    "    i =  np.where(v!=0)\n",
    "    vs = 0.5*(np.sign(np.abs(v[i])-1)+1);\n",
    "    v[i] = (1-vs)*v[i] + vs/np.conj(v[i]);\n",
    "    ind = np.where(a!=0)\n",
    "    b = a[ind[0][0]]*np.poly(v);\n",
    "    \n",
    "#     Return only real coefficients if input was real:\n",
    "    if not(np.sum(np.imag(a))):\n",
    "    \tb = np.real(b)\n",
    "    \n",
    "    return b\n",
    "\n",
    "def numf(h,a,nb):\n",
    "    #NUMF\tFind numerator B given impulse-response h of B/A and denominator A\n",
    "    #   NB is the numerator order.  This function is used by YULEWALK.\n",
    "  \n",
    "\n",
    "    nh = np.max(h.size); \n",
    "    xn=np.concatenate((1,np.zeros((1,nh-1))),axis=None)    \n",
    "    impr = signal.lfilter(np.array([1.0]),a,xn)\n",
    "    toeplitz(impr,np.concatenate((1,np.zeros((1,nb))),axis=None))\n",
    "    \n",
    "    b = np.linalg.lstsq(toeplitz(impr,np.concatenate((1,np.zeros((1,nb))),axis=None)), h.T,rcond=None)[0].T\n",
    "\n",
    "    return b\n",
    "\n",
    "def denf(R,na):\n",
    "    #DENF\tCompute denominator from covariances.\n",
    "    #   A = DENF(R,NA) computes order NA denominator A from covariances \n",
    "    #   R(0)...R(nr) using the Modified Yule-Walker method.  \n",
    "    #   This function is used by YULEWALK.    \n",
    "    nr = np.max(np.size(R));\n",
    "    Rm = toeplitz(R[na:nr-1],R[na:0:-1])\n",
    "    Rhs = - R[na+1:nr];\n",
    "    A = np.concatenate((1,np.linalg.lstsq(Rm, Rhs.T,rcond=None)[0].T),axis=None)\n",
    "    return A\n",
    "\n",
    "\n",
    "def yulewalk(Order, F, M):\n",
    "#YULEWALK Recursive filter design using a least-squares method.\n",
    "#   [B,A] = YULEWALK(N,F,M) finds the N-th order recursive filter\n",
    "#   coefficients B and A such that the filter:\n",
    "#   \t                      -1             -(n-1) \n",
    "#   \t   B(z)   b(1) + b(2)z + .... + b(n)z\n",
    "#   \t   ---- = ---------------------------\n",
    "#   \t                      -1             -(n-1)\n",
    "#   \t   A(z)    1   + a(1)z + .... + a(n)z\n",
    "#\n",
    "#   matches the magnitude frequency response given by vectors F and M.\n",
    "#   Vectors F and M specify the frequency and magnitude breakpoints for\n",
    "#   the filter such that PLOT(F,M) would show a plot of the desired\n",
    "#   frequency response. The frequencies in F must be between 0.0 and 1.0,\n",
    "#   with 1.0 corresponding to half the sample rate. They must be in\n",
    "#   increasing order and start with 0.0 and end with 1.0. \n",
    "#\n",
    "#   # Example:\n",
    "#   #   Design an 8th-order lowpass filter and overplot the desired  \n",
    "#   #   frequency response with the actual frequency response.\n",
    "#\n",
    "#   f = [0 0.6 0.6 1];      # Frequency breakpoints \n",
    "#   m = [1 1 0 0];          # Magnitude breakpoints\n",
    "#   [b,a] = yulewalk(8,f,m);# Filter design using a least-squares method\n",
    "#   [h,w] = freqz(b,a,128); # Frequency response of filter\n",
    "#   plot(f,m,w/pi,abs(h),'--')\n",
    "#   legend('Ideal','yulewalk Designed')\n",
    "#   title('Comparison of Frequency Response Magnitudes')\n",
    "#\n",
    "#   See also FIR1, BUTTER, CHEBY1, CHEBY2, ELLIP, FREQZ and FILTER.\n",
    "\n",
    "#   The YULEWALK function performs a least squares fit in the time\n",
    "#   domain. The denominator coefficients {a(1),...,a(NA)} are computed\n",
    "#   by the so called \"modified Yule Walker\" equations, using NR\n",
    "#   correlation coefficients computed by inverse Fourier transformation\n",
    "#   of the specified frequency response H.\n",
    "#   The numerator is computed by a four step procedure. First, a numerator\n",
    "#   polynomial corresponding to an additive decomposition of the power \n",
    "#   frequency response is computed. Next, the complete frequency response\n",
    "#   corresponding to the numerator and denominator polynomials is\n",
    "#   evaluated. Then a spectral factorization technique is used to\n",
    "#   obtain the impulse response of the filter. Finally, the numerator\n",
    "#   polynomial is obtained by a least squares fit to this impulse\n",
    "#   response. For a more detailed explanation of the algorithm see \n",
    "#   B. Friedlander and B. Porat, \"The Modified Yule-Walker Method\n",
    "#   of ARMA Spectral Estimation,\" IEEE Transactions on Aerospace\n",
    "#   Electronic Systems, Vol. AES-20, No. 2, pp. 158-173, March 1984.\n",
    "\n",
    "    npt = 512\n",
    "    lap = np.fix(npt/25)       \n",
    "    mf = F.size\n",
    "    mm = M.size\n",
    "    npt = npt + 1  # For [dc 1 2 ... nyquist].\n",
    "    Ht = np.array(np.zeros((1,npt)))\n",
    "    nint=mf-1;\n",
    "    df = np.diff(F)\n",
    "    \n",
    "    nb = 0\n",
    "    Ht[0][0]=M[0]\n",
    "    for i in range(nint):\n",
    "        if (df[i] == 0):\n",
    "            nb = nb - lap/2\n",
    "            ne = nb + lap\n",
    "        else:\n",
    "            ne = int(np.fix(F[i+1]*npt))-1\n",
    "    \n",
    "        j=np.arange(nb,ne+1)\n",
    "        if (ne == nb):\n",
    "            inc = 0\n",
    "        else:\n",
    "            inc = (j-nb)/(ne-nb)\n",
    "        \n",
    "        Ht[0][nb:ne+1] = np.array(inc*M[i+1] + (1 - inc)*M[i])\n",
    "        nb = ne + 1;\n",
    "\n",
    "\n",
    "    Ht = np.concatenate((Ht,Ht[0][-2:0:-1]), axis=None)\n",
    "    n = Ht.size\n",
    "    n2 = np.fix((n+1)/2)\n",
    "    nb = Order\n",
    "    nr = 4*Order;\n",
    "    nt = np.arange(0,nr)\n",
    "    \n",
    "    #    compute correlation function of magnitude squared response    \n",
    "    R = np.real(np.fft.ifft(Ht*Ht))\n",
    "    R  = R[0:nr]*(0.54+0.46*np.cos(np.pi*nt/(nr-1)))     # pick NR correlations \n",
    "    \n",
    "    #     Form window to be used in extracting the right \"wing\" of two-sided covariance sequence\n",
    "    Rwindow = np.concatenate((1/2,np.ones((1,int(n2-1))),np.zeros((1,int(n-n2)))),axis=None) \n",
    "    A = polystab(denf(R,Order));            \t# compute denominator\n",
    "    \n",
    "    Qh = numf(np.concatenate((R[0]/2,R[1:nr]),axis=None),A,Order);\t# compute additive decomposition\n",
    "    \n",
    "    _,Ss = 2*np.real(scipy.signal.freqz(Qh,A, worN=n,whole=True)) # compute impulse response\n",
    "    \n",
    "    hh = np.real(np.fft.ifft(np.exp(np.fft.fft( Rwindow*np.real(np.fft.ifft(np.log(Ss))) ))))\n",
    "    B  = np.real(numf(hh[0:nr],A,nb));\n",
    "    \n",
    "    return B,A\n",
    "\n",
    "\n",
    "def YW_filter(Data,srate,iirstate_in):\n",
    "#     FilterB, FilterA : Coefficients of an IIR filter that is used to shape the spectrum of the signal\n",
    "#                      when calculating artifact statistics. The output signal does not go through\n",
    "#                      this filter. This is an optional way to tune the sensitivity of the algorithm\n",
    "#                      to each frequency component of the signal. The default filter is less\n",
    "#                      sensitive at alpha and beta frequencies and more sensitive at delta (blinks)\n",
    "#                      and gamma (muscle) frequencies. Default: \n",
    "#                      [b,a] = yulewalk(8,[[0 2 3 13 16 40 min(80,srate/2-1)]*2/srate 1],[3 0.75 0.33 0.33 1 1 3 3]);\n",
    "    [C,S] = Data.shape\n",
    "    F=np.array([0,2,3,13,16,40,np.minimum(80.0,(srate/2.0)-1.0),srate/2.0])*2.0/srate\n",
    "    M = np.array([3,0.75,0.33,0.33,1,1,3,3])\n",
    "    B,A = yulewalk(8,F,M)\n",
    "    \n",
    "    # apply the signal shaping filter and initialize the IIR filter state\n",
    "    DataFilt = np.zeros((C,S))\n",
    "    iirstate = np.zeros((C,len(A)-1))\n",
    "    zi = signal.lfilter_zi(B, A)\n",
    "    for ichan in range(C):\n",
    "        if (iirstate_in is None):\n",
    "#            DataFilt[ichan,:], iirstate[ichan,:] = signal.lfilter(B,A,Data[ichan,:],zi=zi*0)#zi*Data[ichan,0])\n",
    "            DataFilt[ichan,:], iirstate[ichan,:] = signal.lfilter(B,A,Data[ichan,:],zi=zi*Data[ichan,0])\n",
    "        else:\n",
    "            DataFilt[ichan,:], iirstate[ichan,:] = signal.lfilter(B,A,Data[ichan,:],zi=iirstate_in[ichan,:])\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "    return DataFilt, iirstate\n",
    "\n",
    "def AddVirtualEogChannels(raw,ChanName4VEOG,ChanName4HEOG_l,ChanName4HEOG_r):\n",
    "    FlagVEOG = False\n",
    "    FlagHEOG_L = False\n",
    "    FlagHEOG_R = False\n",
    "    FlagHEOG = True \n",
    "    \n",
    "    if ChanName4VEOG is not None:               \n",
    "        rawSelecChan4Veog  = raw.copy().pick_channels(ChanName4VEOG)\n",
    "        rawVEogData = np.zeros((1, rawSelecChan4Veog.n_times), dtype='float')\n",
    "        rawVEogData[0,:] = (rawSelecChan4Veog.get_data(picks=range(len(ChanName4VEOG))).sum(axis=0))\n",
    "        FlagVEOG = True\n",
    "\n",
    "     # Create virtual Horizontal EOG\n",
    "    if (ChanName4HEOG_l is not None) : \n",
    "        rawSelecChan4Heog_l = raw.copy().pick_channels(ChanName4HEOG_l)\n",
    "        rawHEogL_Data = np.zeros((1, rawSelecChan4Heog_l.n_times), dtype='float')\n",
    "        rawHEogL_Data[0,:] = (rawSelecChan4Heog_l.get_data(picks=range(len(ChanName4HEOG_l))).sum(axis=0))\n",
    "        FlagHEOG_L = True\n",
    "        \n",
    "        \n",
    "    if (ChanName4HEOG_r is not None):\n",
    "        rawSelecChan4Heog_r = raw.copy().pick_channels(ChanName4HEOG_r)\n",
    "        rawHEogR_Data = np.zeros((1, rawSelecChan4Heog_r.n_times), dtype='float')\n",
    "        rawHEogR_Data[0,:] = (rawSelecChan4Heog_r.get_data(picks=range(len(ChanName4HEOG_r))).sum(axis=0))\n",
    "        FlagHEOG_R = True\n",
    "        \n",
    "    if FlagHEOG_L:\n",
    "        if FlagHEOG_R:\n",
    "            rawHEogData = rawHEogL_Data - rawHEogR_Data\n",
    "        else:\n",
    "            rawHEogData = rawHEogL_Data\n",
    "    else:\n",
    "        if FlagHEOG_R:\n",
    "            rawHEogData = rawHEogR_Data\n",
    "        else:\n",
    "            FlagHEOG = False\n",
    "    \n",
    "    rawWithVirtEOG = raw.copy()\n",
    "    # we have VEOG\n",
    "    ################################Modification#################\n",
    "    FlagVEOG = False\n",
    "    if FlagVEOG:\n",
    "        infoVEog = mne.create_info(['VEOG'], rawWithVirtEOG.info['sfreq'], ['eeg'])\n",
    "        VEogRawArray  = mne.io.RawArray(rawVEogData, infoVEog)\n",
    "        rawWithVirtEOG.add_channels([VEogRawArray], force_update_info=True)\n",
    "            \n",
    "    if FlagHEOG:\n",
    "        infoHEog = mne.create_info(['HEOG'], rawWithVirtEOG.info['sfreq'], ['eeg'])\n",
    "        HEogRawArray  = mne.io.RawArray(rawHEogData, infoHEog)\n",
    "        rawWithVirtEOG.add_channels([HEogRawArray], force_update_info=True)\n",
    "    \n",
    "    return rawWithVirtEOG\n",
    "\n",
    "#Estimate the mean and standard deviation of clean EEG from contaminated data.\n",
    "def fit_eeg_distribution(X,min_clean_fraction,max_dropout_fraction,quants,step_sizes,beta):\n",
    "    \n",
    "    # sort data so we can access quantiles directly  \n",
    "    X = np.sort(X)\n",
    "    n = len(X);\n",
    "    \n",
    "    # calc z bounds for the truncated standard generalized Gaussian pdf and pdf rescaler\n",
    "    quants=np.array(quants)\n",
    "    zbounds=[]\n",
    "    rescale=[]\n",
    "    for b in range(len(beta)):\n",
    "        zbounds.append( np.sign(quants-1/2) * scipy.special.gammaincinv(1/beta[b],np.sign(quants-1/2)*(2*quants-1))**(1/beta[b]))\n",
    "        rescale.append(beta[b]/(2*scipy.special.gamma(1/beta[b])))\n",
    "        \n",
    "    # determine the quantile-dependent limits for the grid search\n",
    "    lower_min = np.min(quants)                   # we can generally skip the tail below the lower quantile\n",
    "    max_width = np.diff(quants)                   # maximum width is the fit interval if all data is clean\n",
    "    min_width = min_clean_fraction*max_width   # minimum width of the fit interval, as fraction of data\n",
    "\n",
    "\n",
    "    rowval = np.array(np.round(n*(np.arange(lower_min,lower_min+max_dropout_fraction+ (step_sizes[0]*1e-9),step_sizes[0]))))\n",
    "    colval = np.array(np.arange(0,int(np.round(n*max_width))))\n",
    "    newX=[]\n",
    "    for iX in range(len(colval)):\n",
    "        newX.append(X[np.int_(iX+rowval)])\n",
    "\n",
    "    X1=newX[0]\n",
    "    newX=newX-np.matlib.repmat(X1,len(colval),1)\n",
    "    \n",
    "    opt_val = np.inf;\n",
    "    \n",
    "    for m in (np.round(n*np.arange(max_width,min_width,-step_sizes[1]))):\n",
    "        mcurr = int(m-1)\n",
    "        nbins = int(np.round(3*np.log2(1+m/2)))\n",
    "        \n",
    "        rowval = np.array(nbins/newX[mcurr])\n",
    "        H=newX[0:int(m)]*np.matlib.repmat(rowval,int(m),1)\n",
    "        \n",
    "        HistAll=[]        \n",
    "        for ih in range(len(rowval)):\n",
    "            histcurr = np.histogram(H[:,ih], bins=np.arange(0,nbins+1))\n",
    "            HistAll.append(histcurr[0])\n",
    "        \n",
    "        HistAll=np.int_(np.transpose(HistAll))\n",
    "        HistAll = np.vstack((HistAll,np.zeros(len(rowval), dtype=int)))\n",
    "        logq = np.log(HistAll + 0.01)\n",
    "        \n",
    "        # for each shape value...\n",
    "        for b in range(len(beta)):\n",
    "            bounds = zbounds[b]    \n",
    "            x= bounds[0]+(np.arange(0.5,nbins+0.5)/nbins*np.diff(bounds))\n",
    "            p = np.exp(-np.abs(x)**beta[b])*rescale[b]\n",
    "            p=p/np.sum(p)\n",
    "            \n",
    "            # calc KL divergences        \n",
    "            kl = np.sum((np.transpose(np.matlib.repmat(p,logq.shape[1],1)))*((np.transpose(np.matlib.repmat(np.log(p),logq.shape[1],1))) - logq[0:-1,:]),axis=0) + np.log(m)\n",
    "            \n",
    "            # update optimal parameters\n",
    "            min_val = np.min(kl)\n",
    "            idx =np.argmin(kl)\n",
    "            \n",
    "            if (min_val < opt_val):\n",
    "                opt_val = min_val;\n",
    "                opt_beta = beta[b];\n",
    "                opt_bounds = bounds;\n",
    "                opt_lu = [X1[idx],(X1[idx] + newX[int(m-1),idx])]\n",
    "                \n",
    "    \n",
    "    # recover distribution parameters at optimum\n",
    "    alpha = (opt_lu[1]-opt_lu[0])/np.diff(opt_bounds);\n",
    "    mu = opt_lu[0]-opt_bounds[0]*alpha;\n",
    "    beta = opt_beta;\n",
    "    \n",
    "    # calculate the distribution's standard deviation from alpha and beta\n",
    "    sig = np.sqrt((alpha**2)*scipy.special.gamma(3/beta)/scipy.special.gamma(1/beta))\n",
    "    \n",
    "    return mu,sig,alpha,beta\n",
    "\n",
    "def block_geometric_median(X,blocksize):\n",
    "    # Calculate a blockwise geometric median (faster and less memory-intensive \n",
    "    # than the regular geom_median function).\n",
    "    #\n",
    "    # This statistic is not robust to artifacts that persist over a duration that\n",
    "    # is significantly shorter than the blocksize.\n",
    "    #\n",
    "    # In:\n",
    "    #   X : the data (#observations x #variables)\n",
    "    #   blocksize : the number of successive samples over which a regular mean \n",
    "    #               should be taken\n",
    "    #   tol : tolerance (default: 1.e-5)\n",
    "    #   y : initial value (default: median(X))\n",
    "    #   max_iter : max number of iterations (default: 500)\n",
    "    #\n",
    "    # Out:\n",
    "    #   g : geometric median over X\n",
    "    #\n",
    "    # Notes:\n",
    "    #   This function is noticably faster if the length of the data is divisible by the block size.\n",
    "    #   Uses the GPU if available.\n",
    "    # \n",
    "    \n",
    "    if (blocksize > 1):\n",
    "        o,v=X.shape       # #observations & #variables\n",
    "        r = np.mod(o,blocksize)  # #rest in last block\n",
    "        b = int((o-r)/blocksize)   # #blocks\n",
    "        Xreshape = np.zeros((b+1,v))\n",
    "        if (r > 0):\n",
    "           Xreshape[0:b,:] = np.reshape( np.sum(np.reshape(X[0:(o-r),:],(blocksize,b*v)),axis=0), (b,v))\n",
    "           Xreshape[b,:] = np.sum(X[(o-r+1):o,:],axis=0)*(blocksize/r)\n",
    "        else:\n",
    "           Xreshape =   np.reshape(np.sum(np.reshape(X,(blocksize,b*v)),axis=0),(b,v))\n",
    "        X=Xreshape\n",
    "    tol = 1.e-5\n",
    "    y = np.median(X,axis=0)\n",
    "    max_iter = 500\n",
    "    y = geometric_median(X,tol,y,max_iter)/blocksize\n",
    "    \n",
    "    return y\n",
    "\n",
    "\n",
    "def asr_calibrate(Data,srate,cutoff):\n",
    "    # Calibration function for the Artifact Subspace Reconstruction (ASR) method.\n",
    "    # State = asr_calibrate(Data,SamplingRate,Cutoff,BlockSize,FilterB,FilterA,WindowLength,WindowOverlap,MaxDropoutFraction,MinCleanFraction)\n",
    "    #\n",
    "    # The input to this data is a multi-channel time series of calibration data. In typical uses the\n",
    "    # calibration data is clean resting EEG data of ca. 1 minute duration (can also be longer). One can\n",
    "    # also use on-task data if the fraction of artifact content is below the breakdown point of the\n",
    "    # robust statistics used for estimation (50# theoretical, ~30# practical). If the data has a\n",
    "    # proportion of more than 30-50# artifacts then bad time windows should be removed beforehand. This\n",
    "    # data is used to estimate the thresholds that are used by the ASR processing function to identify\n",
    "    # and remove artifact components.\n",
    "    #\n",
    "    # The calibration data must have been recorded for the same cap design from which data for cleanup\n",
    "    # will be recorded, and ideally should be from the same session and same subject, but it is possible\n",
    "    # to reuse the calibration data from a previous session and montage to the extent that the cap is\n",
    "    # placed in the same location (where loss in accuracy is more or less proportional to the mismatch\n",
    "    # in cap placement).\n",
    "    #\n",
    "    # The calibration data should have been high-pass filtered (for example at 0.5Hz or 1Hz using a\n",
    "    # Butterworth IIR filter).\n",
    "    #\n",
    "    # In:\n",
    "    #   Data : Calibration data [#channels x #samples]; *zero-mean* (e.g., high-pass filtered) and\n",
    "    #          reasonably clean EEG of not much less than 30 seconds length (this method is typically\n",
    "    #          used with 1 minute or more).\n",
    "    #\n",
    "    #   SamplingRate : Sampling rate of the data, in Hz.\n",
    "    #\n",
    "    #\n",
    "    #   The following are optional parameters (the key parameter of the method is the RejectionCutoff):\n",
    "    #\n",
    "    #   RejectionCutoff: Standard deviation cutoff for rejection. Data portions whose variance is larger\n",
    "    #                    than this threshold relative to the calibration data are considered missing\n",
    "    #                    data and will be removed. The most aggressive value that can be used without\n",
    "    #                    losing too much EEG is 2.5. A quite conservative value would be 5. Default: 5.\n",
    "    #\n",
    "    #   Blocksize : Block size for calculating the robust data covariance and thresholds, in samples;\n",
    "    #               allows to reduce the memory and time requirements of the robust estimators by this \n",
    "    #               factor (down to Channels x Channels x Samples x 16 / Blocksize bytes). Default: 10\n",
    "    #\n",
    "    #   FilterB, FilterA : Coefficients of an IIR filter that is used to shape the spectrum of the signal\n",
    "    #                      when calculating artifact statistics. The output signal does not go through\n",
    "    #                      this filter. This is an optional way to tune the sensitivity of the algorithm\n",
    "    #                      to each frequency component of the signal. The default filter is less\n",
    "    #                      sensitive at alpha and beta frequencies and more sensitive at delta (blinks)\n",
    "    #                      and gamma (muscle) frequencies. Default: \n",
    "    #                      [b,a] = yulewalk(8,[[0 2 3 13 16 40 min(80,srate/2-1)]*2/srate 1],[3 0.75 0.33 0.33 1 1 3 3]);\n",
    "    #\n",
    "    #   WindowLength : Window length that is used to check the data for artifact content. This is \n",
    "    #                  ideally as long as the expected time scale of the artifacts but short enough to \n",
    "    #\t\t\t\t   allow for several 1000 windows to compute statistics over. Default: 0.5.\n",
    "    #\n",
    "    #   WindowOverlap : Window overlap fraction. The fraction of two successive windows that overlaps.\n",
    "    #                   Higher overlap ensures that fewer artifact portions are going to be missed (but\n",
    "    #                   is slower). Default: 0.66\n",
    "    #\n",
    "    #   MaxDropoutFraction : Maximum fraction of windows that can be subject to signal dropouts \n",
    "    #                        (e.g., sensor unplugged), used for threshold estimation. Default: 0.1\n",
    "    #\n",
    "    #   MinCleanFraction : Minimum fraction of windows that need to be clean, used for threshold\n",
    "    #                      estimation. Default: 0.25\n",
    "    #\n",
    "    #\n",
    "    # Out:\n",
    "    #   State : initial state struct for asr_process\n",
    "    \n",
    "    [C,S] = Data.shape\n",
    "    print('C is')\n",
    "    print(C)\n",
    "    blocksize = 10\n",
    "    window_len = 0.5\n",
    "    window_overlap = 0.66\n",
    "    \n",
    "    max_dropout_fraction = 0.1\n",
    "    min_clean_fraction = 0.25\n",
    "#    F=np.array([0,2,3,13,16,40,np.minimum(80.0,(srate/2.0)-1.0),srate/2.0])*2.0/srate\n",
    "#    M = np.array([3,0.75,0.33,0.33,1,1,3,3])\n",
    "#    B,A = tools.yulewalk(8,F,M)\n",
    "#    \n",
    "#    # apply the signal shaping filter and initialize the IIR filter state\n",
    "#    SigFilt = np.zeros((C,S))\n",
    "#    iirstate = np.zeros((C,len(A)-1))\n",
    "#    zi = signal.lfilter_zi(B, A)\n",
    "#    for ichan in range(C):\n",
    "#        SigFilt[ichan,:], iirstate[ichan,:] = signal.lfilter(B,A,Data[ichan,:],zi=zi*0)#zi*Data[ichan,0])\n",
    "    Data = Data.T\n",
    "    U = np.zeros((len(np.arange(0,S,blocksize)),C*C))\n",
    "    for k in range(blocksize):\n",
    "        rangevect = np.minimum(S-1,np.arange(k,S+k,blocksize))\n",
    "        Xrange = Data[rangevect,:]\n",
    "        for ic in range(C):\n",
    "            islice = np.arange((ic*C),((ic+1)*C),1,dtype=int)\n",
    "            U[:,islice] = U[:,islice] + (Xrange*np.transpose(np.matlib.repmat(Xrange[:,ic],C,1)))\n",
    "        \n",
    "\n",
    "    # get the mixing matrix M\n",
    "    M = scipy.linalg.sqrtm(np.real(np.reshape(block_geometric_median(U/blocksize,1),(C,C))));\n",
    "    \n",
    "    # window length for calculating thresholds\n",
    "    N = int(np.round(window_len*srate))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # get the threshold matrix T\n",
    "    print('Determining per-component thresholds...');\n",
    "    \n",
    "    D,Vtmp = scipy.linalg.eig(M)\n",
    "    V=Vtmp[:,np.argsort(D)]\n",
    "    \n",
    "    X = np.abs(np.dot(Data,V));\n",
    "    \n",
    "    offsets = np.int_(np.arange(0,S-N,np.round(N*(1-window_overlap))))\n",
    "    truncate_quant = [0.0220,0.6000]\n",
    "    step_sizes = [0.01,0.01]\n",
    "    shape_range = np.linspace(1.7,3.5,13)\n",
    "    mu=np.zeros(C)\n",
    "    sig=np.zeros(C)\n",
    "    for ichan in range(C):\n",
    "        rms = X[:,ichan]**2\n",
    "        Y=[]\n",
    "        for joffset in offsets:\n",
    "            Y.append(np.sqrt(np.sum(rms[joffset:joffset+N])/N))\n",
    "            \n",
    "        Y=np.transpose(Y)\n",
    "        mu[ichan],sig[ichan],alpha,beta = fit_eeg_distribution(Y, min_clean_fraction, max_dropout_fraction,truncate_quant, step_sizes,shape_range)\n",
    "    \n",
    "    T = np.dot(np.diag(mu + cutoff*sig),V.T)\n",
    "#    print('mu',mu)\n",
    "#    print('sig',sig)\n",
    "#    \n",
    "    print('done.');\n",
    "    calibASRparam= {'M':M,'T':T}\n",
    "    return calibASRparam\n",
    "            #'cov',[],'carry',[],'iir',iirstate,'last_R',[],'last_trivial',true}\n",
    "    # initialize the remaining filter state\n",
    "    #state = struct('M',M,'T',T,'B',B,'A',A,'cov',[],'carry',[],'iir',iirstate,'last_R',[],'last_trivial',true);\n",
    "    \n",
    "\n",
    "def clean_windows(Signal,srate,max_bad_channels,zthresholds,window_len):\n",
    "# Remove periods with abnormally high-power content from continuous data.\n",
    "# [Signal,Mask] = clean_windows(Signal,MaxBadChannels,PowerTolerances,WindowLength,WindowOverlap,MaxDropoutFraction,Min)\n",
    "#\n",
    "# This function cuts segments from the data which contain high-power artifacts. Specifically,\n",
    "# only windows are retained which have less than a certain fraction of \"bad\" channels, where a channel\n",
    "# is bad in a window if its power is above or below a given upper/lower threshold (in standard \n",
    "# deviations from a robust estimate of the EEG power distribution in the channel).\n",
    "#\n",
    "# In:\n",
    "#   Signal         : Continuous data set, assumed to be appropriately high-passed (e.g. >1Hz or\n",
    "#                    0.5Hz - 2.0Hz transition band)\n",
    "#\n",
    "#   MaxBadChannels : The maximum number or fraction of bad channels that a retained window may still\n",
    "#                    contain (more than this and it is removed). Reasonable range is 0.05 (very clean\n",
    "#                    output) to 0.3 (very lax cleaning of only coarse artifacts). Default: 0.2.\n",
    "#\n",
    "#   PowerTolerances: The minimum and maximum standard deviations within which the power of a channel\n",
    "#                    must lie (relative to a robust estimate of the clean EEG power distribution in \n",
    "#                    the channel) for it to be considered \"not bad\". Default: [-3.5 5].\n",
    "#\n",
    "#\n",
    "#   The following are detail parameters that usually do not have to be tuned. If you can't get\n",
    "#   the function to do what you want, you might consider adapting these to your data.\n",
    "#\n",
    "#   WindowLength    : Window length that is used to check the data for artifact content. This is \n",
    "#                     ideally as long as the expected time scale of the artifacts but not shorter \n",
    "#                     than half a cycle of the high-pass filter that was used. Default: 1.\n",
    "#\n",
    "#   WindowOverlap : Window overlap fraction. The fraction of two successive windows that overlaps.\n",
    "#                   Higher overlap ensures that fewer artifact portions are going to be missed (but\n",
    "#                   is slower). (default: 0.66)\n",
    "# \n",
    "#   MaxDropoutFraction : Maximum fraction that can have dropouts. This is the maximum fraction of\n",
    "#                        time windows that may have arbitrarily low amplitude (e.g., due to the\n",
    "#                        sensors being unplugged). (default: 0.1)\n",
    "#\n",
    "#   MinCleanFraction : Minimum fraction that needs to be clean. This is the minimum fraction of time\n",
    "#                      windows that need to contain essentially uncontaminated EEG. (default: 0.25)\n",
    "#\n",
    "#   \n",
    "#   The following are expert-level parameters that you should not tune unless you fully understand\n",
    "#   how the method works.\n",
    "#\n",
    "#   TruncateQuantile : Truncated Gaussian quantile. Quantile range [upper,lower] of the truncated\n",
    "#                      Gaussian distribution that shall be fit to the EEG contents. (default: [0.022 0.6])\n",
    "#\n",
    "#   StepSizes : Grid search stepping. Step size of the grid search, in quantiles; separately for\n",
    "#               [lower,upper] edge of the truncated Gaussian. The lower edge has finer stepping\n",
    "#               because the clean data density is assumed to be lower there, so small changes in\n",
    "#               quantile amount to large changes in data space. (default: [0.01 0.01])\n",
    "#\n",
    "#   ShapeRange : Shape parameter range. Search range for the shape parameter of the generalized\n",
    "#                Gaussian distribution used to fit clean EEG. (default: 1.7:0.15:3.5)\n",
    "#\n",
    "# Out:\n",
    "#   SignalClean : data set with bad time periods removed.\n",
    "#\n",
    "#   Mask   : mask of retained samples (logical array)\n",
    "\n",
    "\n",
    "    window_overlap = 0.66\n",
    "    max_dropout_fraction = 0.1\n",
    "    min_clean_fraction = 0.25\n",
    "    truncate_quant = [0.0220,0.6000]\n",
    "    step_sizes = [0.01,0.01]\n",
    "    shape_range = np.linspace(1.7,3.5,13)\n",
    "    max_bad_channels = np.round(Signal.shape[0]*max_bad_channels);\n",
    "    \n",
    "#    Signal = Signal *1e6\n",
    "    [C,S] = Signal.shape;\n",
    "    N = int(window_len*srate);\n",
    "    wnd = np.arange(0,N);\n",
    "    print(S-N,np.round(N*(1-window_overlap)))\n",
    "    \n",
    "    ############################ S-N ################################ is negative\n",
    "    offsets = np.int_(np.arange(S-N,0,np.round(N*(1-window_overlap))))\n",
    "\n",
    "    print('Determining time window rejection thresholds...')\n",
    "    print('for each channel...')\n",
    "    \n",
    "    print('C is {}'.format(C))\n",
    "    wz=np.array([])\n",
    "    for ichan in range(C):\n",
    "        X = Signal[ichan,:]**2\n",
    "        Y=[]\n",
    "        for joffset in offsets:\n",
    "            Y.append(np.sqrt(np.sum(X[joffset:joffset+N])/N))\n",
    "            \n",
    "        Y=np.transpose(Y)\n",
    "        mu,sig,alpha,beta = fit_eeg_distribution(Y, min_clean_fraction, max_dropout_fraction,truncate_quant, step_sizes,shape_range)\n",
    "        if (ichan==0):\n",
    "           wz = (Y-mu)/sig\n",
    "        else:\n",
    "            wz=np.vstack((wz,np.array((Y-mu)/sig)))\n",
    "\n",
    "    # sort z scores into quantiles\n",
    "    swz = np.sort(wz,axis=0)\n",
    "    \n",
    "    #    determine which windows to remove\n",
    "    if (np.max(zthresholds)>0):\n",
    "        remove_mask1 = swz[-(np.int(max_bad_channels)+1),:] > np.max(zthresholds)\n",
    "              \n",
    "    if (np.min(zthresholds)<0):\n",
    "        remove_mask2 = swz[1+np.int(max_bad_channels-1),:] < np.min(zthresholds)\n",
    "        \n",
    "    remove_mask=np.logical_or(remove_mask1, remove_mask2)\n",
    "    removed_windows = np.where(remove_mask)\n",
    "    \n",
    "    sample_maskidx = []\n",
    "    for iremoved in range(len(removed_windows[0])):\n",
    "        if (iremoved==0):\n",
    "            sample_maskidx=np.arange(offsets[removed_windows[0][iremoved]],offsets[removed_windows[0][iremoved]]+N)\n",
    "        else:\n",
    "            sample_maskidx=np.vstack((sample_maskidx,(np.arange(offsets[removed_windows[0][iremoved]],offsets[removed_windows[0][iremoved]]+N))))\n",
    "\n",
    "    sample_mask2remove = np.unique(sample_maskidx)\n",
    "    \n",
    "    SignalClean = np.delete(Signal,sample_mask2remove,1)\n",
    "    sample_mask = np.ones((1, S), dtype=bool)\n",
    "    ######################### modification add int######################## \n",
    "    sample_mask[0,int(sample_mask2remove)]=False\n",
    "    \n",
    "    return SignalClean,sample_mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def raw_asrcalibration(raw,ChanName4VEOG, cutoff,Yule_Walker_filtering):\n",
    "# Compute ASR calibration from raw object\n",
    "    #\n",
    "    # raw : The raw data used for ASR calibration\n",
    "    # ChanName4VEOG : Nome of channels to estimate a vertical EOG (blink detection) ex : ChanName4VEOG = ['Fp1','Fp2']\n",
    "    # cutoff : parameter that determines the rejection threshold\n",
    "    # Yule_Walker_filtering : Apply Yule_Walker filter or not \n",
    "      \n",
    "    # Apply Yule-Walker filter\n",
    "    rawCalibAsr=raw.copy()\n",
    "    if Yule_Walker_filtering:\n",
    "        rawCalibAsr._data,iirstate = YW_filter(rawCalibAsr._data,rawCalibAsr.info['sfreq'],None)\n",
    "    \n",
    "    \n",
    "    ## Blink detection\n",
    "    # compute virtual vertical EOG to detect blinks\n",
    "    ChanName4HEOG_l = None\n",
    "    ChanName4HEOG_r = None\n",
    "    rawWithVirtEog = AddVirtualEogChannels(rawCalibAsr,ChanName4VEOG,ChanName4HEOG_l,ChanName4HEOG_r)\n",
    "    \n",
    "    # Find time location of blinks\n",
    "    rawVEOG =rawWithVirtEog.pick_channels(['VEOG'])\n",
    "    VEOG_data = np.squeeze(rawVEOG.get_data())\n",
    "    peak_locs, peak_eeg = peak_finder(VEOG_data,thresh=75e-6)\n",
    "    \n",
    "    lengthblink = 0.5*raw.info['sfreq']; #500ms (in ms because the findpeaks return values in ms)\n",
    "    startremoveblink = peak_locs-(lengthblink/2)\n",
    "    stopremoveblink = peak_locs+(lengthblink/2)\n",
    "    NbsampCalibAsrWindow = len(VEOG_data)\n",
    "    startremoveblink = np.abs((startremoveblink>0)*startremoveblink)\n",
    "    stopremoveblink =  (stopremoveblink>NbsampCalibAsrWindow-1)*NbsampCalibAsrWindow + (stopremoveblink<NbsampCalibAsrWindow-1)*stopremoveblink\n",
    "    Mask=np.zeros(NbsampCalibAsrWindow)\n",
    "    for ix2remove in range(len(startremoveblink)):\n",
    "        Mask[int(startremoveblink[ix2remove]):int(stopremoveblink[ix2remove])]=1\n",
    "    \n",
    "    rawdata_noblink = np.delete(raw.get_data(),np.where(Mask),axis=1)\n",
    "    SignalCalib=np.delete(rawdata_noblink,np.where(np.abs(rawdata_noblink)>50e-6)[1],axis=1)\n",
    "\n",
    "  \n",
    "    ref_maxbadchannels = 0.2;\n",
    "    ref_tolerances = [-3.5,5.5];\n",
    "    ref_wndlen = 1;\n",
    "    \n",
    "    SignalClean,sample_mask = clean_windows(SignalCalib,raw.info['sfreq'],ref_maxbadchannels,ref_tolerances,ref_wndlen);\n",
    "    srate = raw.info['sfreq']\n",
    "    \n",
    "    \n",
    "    state = asr_calibrate(SignalClean,srate,cutoff)\n",
    "    return state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
