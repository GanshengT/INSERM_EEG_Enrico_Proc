{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scp -r statistic arnaud.poublan-couzardot@10.69.168.30:/dycog/meditation/ERC/Analyses/MMN/spectral_analysis/results/\n",
    "    hVDi58&+0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### group effet of  FA for all conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get bp matrice for 6 baseline  expert/novice  VD FA OP -baseline\n",
    "\n",
    "import pickle\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.time_frequency import psd_array_multitaper\n",
    "from scipy.integrate import simps\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import sys\n",
    "from mne.channels import find_ch_connectivity\n",
    "from scipy.stats.distributions import f,t\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "precleaned_epochs_path = '/home/gansheng.tan/process_mne/INSERM_EEG_Enrico_Proc/data_eeglab/full_epochs_data/'\n",
    "fmin = 1\n",
    "fmax = 100\n",
    "\n",
    "\n",
    "def getBpAbs4allChannels(epochs,rhythm):\n",
    "    wavebands = {'alpha':[8,12],'theta':[3,7],'beta':[13,24],'lowG':[25,40],'highG':[60,90]}\n",
    "    if rhythm in wavebands.keys():\n",
    "        low,high =  wavebands[rhythm]\n",
    "    else:\n",
    "        print('not such rhythm')\n",
    "    bpAbs_4Epochs=[]\n",
    "    data = epochs.get_data(picks=['eeg'])\n",
    "    for num_epochs in range(data.shape[0]):\n",
    "        sf = epochs.info['sfreq']\n",
    "        bpAbs_4allchannels = []\n",
    "        psd, freqs = psd_array_multitaper(data[num_epochs], sf, fmin = 1, fmax =100,\n",
    "                          adaptive=True,normalization='full',verbose=0)\n",
    "        psd= np.log10(psd*10e12)\n",
    "        freq_res = freqs[1] - freqs[0]\n",
    "        idx_band = np.logical_and(freqs >= low, freqs <= high)\n",
    "        bp_abs = simps(psd[:,idx_band], dx=freq_res)\n",
    "        bpAbs_4Epochs.append(bp_abs)\n",
    "    bpAbs_mean4Epochs = np.append([bpAbs_4Epochs[0]],bpAbs_4Epochs[1:],axis = 0).mean(axis=0)\n",
    "    return bpAbs_mean4Epochs\n",
    "\n",
    "# alpha bp clustering test - VD OP\n",
    "\n",
    "subjs=['02', '04','07', '11', '12', '14', '16', '18', '19', '21', '22', '26', '28', '30',\n",
    "       '32', '34', '36', '37', '38', '40', '42', '50', '51', '52', '53', '54', '55', '56',\n",
    "       '58', '59','60', '63', '65', '67', '68', '70', '72', '73', '78', '83', '87', '88', \n",
    "       '90', '91', '93', '94', '95', '96','10','25','29','39','57','64','69','80','81','82',\n",
    "       '35','71','79','76','77']\n",
    "\n",
    "# states_codes={'VD':['111.0','112.0','121.0','122.0','131.0','132.0'],\n",
    "#               'FA':['211.0','212.0','221.0','222.0','231.0','232.0'],\n",
    "#               'OP':['311.0','312.0','321.0','322.0','331.0','332.0']}\n",
    "\n",
    "states_codes={'VD':['111.0','112.0'],\n",
    "              'FA':['211.0','212.0'],\n",
    "              'OP':['311.0','312.0']}\n",
    "\n",
    "listNovices = ['02', '04', '07', '10', '11', '12', '14', '16', '18', '19', '21', '22', '26', \n",
    " '28', '29', '30', '32', '34', '35', '36', '37', '38','39', '40', '42', '81', '82', \n",
    " '83', '87', '88', '90', '91', '93', '94', '95', '96']\n",
    "listExperts = ['25', '50','51', '52',\n",
    " '53', '54', '55', '56', '57', '58', '59', '60', '63', '64', '65', '67','68', '69' ,'70' ,\n",
    "               '71', '72', '73', '76', '77', '78' ,'79', '80']\n",
    "\n",
    "\n",
    "bpAbs_mean4Epochs_FA4experts = np.array([])\n",
    "bpAbs_mean4Epochs_FA4novices = np.array([])\n",
    "\n",
    "for expert in listExperts:\n",
    "    precleaned_epochs_fname = precleaned_epochs_path + 'subj0'+expert+'full_epo.fif'\n",
    "    precleaned_epochs = mne.read_epochs(precleaned_epochs_fname, preload=True)\n",
    "    \n",
    "#     precleaned_epochs_VD = precleaned_epochs[states_codes['VD']]\n",
    "#     precleaned_epochs_OP = precleaned_epochs[states_codes['OP']]\n",
    "#     bpAbs_mean4Epochs_VD = getBpAbs4allChannels(precleaned_epochs_VD,'alpha')\n",
    "#     bpAbs_mean4Epochs_OP= getBpAbs4allChannels(precleaned_epochs_OP,'alpha')\n",
    "\n",
    "    precleaned_epochs_VD = precleaned_epochs[states_codes['VD']]\n",
    "    precleaned_epochs_FA = precleaned_epochs[states_codes['FA']]\n",
    "    bpAbs_mean4Epochs_VD = getBpAbs4allChannels(precleaned_epochs_VD,'alpha')\n",
    "    bpAbs_mean4Epochs_FA= getBpAbs4allChannels(precleaned_epochs_FA,'alpha')\n",
    "\n",
    "#     precleaned_epochs_FA = precleaned_epochs[states_codes['FA']]\n",
    "#     precleaned_epochs_OP = precleaned_epochs[states_codes['OP']]\n",
    "#     bpAbs_mean4Epochs_FA = getBpAbs4allChannels(precleaned_epochs_FA,'alpha')\n",
    "#     bpAbs_mean4Epochs_OP= getBpAbs4allChannels(precleaned_epochs_OP,'alpha')\n",
    "    \n",
    "    if len(bpAbs_mean4Epochs_VD4allsubjs)==0:\n",
    "        bpAbs_mean4Epochs_VD4allsubjs = bpAbs_mean4Epochs_VD\n",
    "#         bpRelative_mean4Epochs_VD4allsubjs = bpRelative_mean4Epochs_VD\n",
    "    else:\n",
    "        bpAbs_mean4Epochs_VD4allsubjs = np.vstack((bpAbs_mean4Epochs_VD4allsubjs,bpAbs_mean4Epochs_VD))\n",
    "#         bpRelative_mean4Epochs_VD4allsubjs = np.vstack((bpRelative_mean4Epochs_VD4allsubjs,\n",
    "#                                                         bpRelative_mean4Epochs_VD))\n",
    "        \n",
    "#     if len(bpAbs_mean4Epochs_OP4allsubjs)==0:\n",
    "#         bpAbs_mean4Epochs_OP4allsubjs = bpAbs_mean4Epochs_OP\n",
    "# #         bpRelative_mean4Epochs_OP4allsubjs = bpRelative_mean4Epochs_OP\n",
    "#     else:\n",
    "#         bpAbs_mean4Epochs_OP4allsubjs = np.vstack((bpAbs_mean4Epochs_OP4allsubjs,bpAbs_mean4Epochs_OP))\n",
    "# #         bpRelative_mean4Epochs_OP4allsubjs = np.vstack((bpRelative_mean4Epochs_OP4allsubjs,\n",
    "# #                                                         bpRelative_mean4Epochs_OP))\n",
    "\n",
    "    if len(bpAbs_mean4Epochs_FA4allsubjs)==0:\n",
    "        bpAbs_mean4Epochs_FA4allsubjs = bpAbs_mean4Epochs_FA\n",
    "#         bpRelative_mean4Epochs_OP4allsubjs = bpRelative_mean4Epochs_OP\n",
    "    else:\n",
    "        bpAbs_mean4Epochs_FA4allsubjs = np.vstack((bpAbs_mean4Epochs_FA4allsubjs,bpAbs_mean4Epochs_FA))\n",
    "#         bpRelative_mean4Epochs_OP4allsubjs = np.vstack((bpRelative_mean4Epochs_OP4allsubjs,\n",
    "#                                                         bpRelative_mean4Epochs_OP))\n",
    "        \n",
    "# bpAbs_mean4Epochs2test = [np.expand_dims(bpAbs_mean4Epochs_VD4allsubjs,axis=1),\n",
    "#                           np.expand_dims(bpAbs_mean4Epochs_OP4allsubjs,axis=1)]\n",
    "\n",
    "bpAbs_mean4Epochs2test = [np.expand_dims(bpAbs_mean4Epochs_VD4allsubjs,axis=1),\n",
    "                          np.expand_dims(bpAbs_mean4Epochs_FA4allsubjs,axis=1)]\n",
    "\n",
    "# bpAbs_mean4Epochs2test = [np.expand_dims(bpAbs_mean4Epochs_FA4allsubjs,axis=1),\n",
    "#                           np.expand_dims(bpAbs_mean4Epochs_OP4allsubjs,axis=1)]\n",
    "\n",
    "\n",
    "# with open('/home/gansheng.tan/process_mne/INSERM_EEG_Enrico_Proc/data_eeglab/full_epochs_data/statistic/VDOP_alpha_baseline_Abs'+group+'.txt', \"wb\") as fp:   #Pickling\n",
    "#     pickle.dump(bpAbs_mean4Epochs2test, fp)\n",
    "    \n",
    "with open('/home/gansheng.tan/process_mne/INSERM_EEG_Enrico_Proc/data_eeglab/full_epochs_data/statistic/VDFA_alpha_baseline_Abs'+group+'.txt', \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(bpAbs_mean4Epochs2test, fp)\n",
    "# with open('/home/gansheng.tan/process_mne/INSERM_EEG_Enrico_Proc/data_eeglab/full_epochs_data/statistic/FAOP_alpha_baseline_Abs'+group+'.txt', \"wb\") as fp:   #Pickling\n",
    "#     pickle.dump(bpAbs_mean4Epochs2test, fp)\n",
    "    \n",
    "precleaned_epochs_fname = precleaned_epochs_path + 'subj004full_epo.fif'\n",
    "precleaned_epochs = mne.read_epochs(precleaned_epochs_fname, preload=True)\n",
    "connectivity, ch_names = find_ch_connectivity(precleaned_epochs.info, ch_type='eeg')\n",
    "\n",
    "p_threshold = 0.05\n",
    "# threshold = -t.ppf(p_threshold/2,np.expand_dims(bpAbs_mean4Epochs_VD4allsubjs,axis=1).shape[0]-1)\n",
    "# cluster_stats = mne.stats.spatio_temporal_cluster_1samp_test(np.expand_dims(bpAbs_mean4Epochs_OP4allsubjs,axis=1)-np.expand_dims(bpAbs_mean4Epochs_VD4allsubjs,axis=1), \n",
    "#                                                              n_permutations=10000,tail=0,threshold=threshold,\n",
    "#                                              n_jobs=2, buffer_size=None,verbose=True,\n",
    "#                                              connectivity=connectivity)\n",
    "\n",
    "threshold = -t.ppf(p_threshold/2,np.expand_dims(bpAbs_mean4Epochs_VD4allsubjs,axis=1).shape[0]-1)\n",
    "cluster_stats = mne.stats.spatio_temporal_cluster_1samp_test(np.expand_dims(bpAbs_mean4Epochs_FA4allsubjs,axis=1)-np.expand_dims(bpAbs_mean4Epochs_VD4allsubjs,axis=1), \n",
    "                                                             n_permutations=10000,tail=0,threshold=threshold,\n",
    "                                             n_jobs=2, buffer_size=None,verbose=True,\n",
    "                                             connectivity=connectivity)\n",
    "\n",
    "# threshold = -t.ppf(p_threshold/2,np.expand_dims(bpAbs_mean4Epochs_FA4allsubjs,axis=1).shape[0]-1)\n",
    "# cluster_stats = mne.stats.spatio_temporal_cluster_1samp_test(np.expand_dims(bpAbs_mean4Epochs_OP4allsubjs,axis=1)-np.expand_dims(bpAbs_mean4Epochs_FA4allsubjs,axis=1), \n",
    "#                                                              n_permutations=10000,tail=0,threshold=threshold,\n",
    "#                                              n_jobs=2, buffer_size=None,verbose=True,\n",
    "#                                              connectivity=connectivity)\n",
    "\n",
    "T_obs, clusters, p_values, _ = cluster_stats\n",
    "print(clusters)\n",
    "# good_cluster_inds = np.array(range(len(clusters)))\n",
    "# precleaned_epochs_fname = precleaned_epochs_path + 'subj004full_epo.fif'\n",
    "# precleaned_epochs = mne.read_epochs(precleaned_epochs_fname, preload=True)\n",
    "# pos = mne.find_layout(precleaned_epochs.info).pos\n",
    "# for i_clu, clu_idx in enumerate(good_cluster_inds):\n",
    "#     # unpack cluster information, get unique indices\n",
    "#     time_inds, space_inds = np.squeeze(clusters[clu_idx])\n",
    "#     ch_inds = np.unique(space_inds)\n",
    "#     time_inds = np.unique(time_inds)\n",
    "\n",
    "#     # get topography for bp-mean\n",
    "# #     bp_map = np.squeeze((np.expand_dims(bpAbs_mean4Epochs_OP4allsubjs,axis=1)-np.expand_dims(bpAbs_mean4Epochs_VD4allsubjs,axis=1)).mean(axis=0))\n",
    "# #     bp_map = np.squeeze((np.expand_dims(bpAbs_mean4Epochs_FA4allsubjs,axis=1)-np.expand_dims(bpAbs_mean4Epochs_VD4allsubjs,axis=1)).mean(axis=0))\n",
    "#     bp_map = np.squeeze((np.expand_dims(bpAbs_mean4Epochs_OP4allsubjs,axis=1)-np.expand_dims(bpAbs_mean4Epochs_FA4allsubjs,axis=1)).mean(axis=0))\n",
    "\n",
    "    \n",
    "#     # create spatial mask\n",
    "#     mask = np.zeros((bp_map.shape[0], 1), dtype=bool)\n",
    "#     mask[ch_inds, :] = True\n",
    "\n",
    "#     # initialize figure\n",
    "#     fig, ax_topo = plt.subplots(1, 1, figsize=(10, 3))\n",
    "\n",
    "#     # plot average test statistic and mark significant sensors\n",
    "#     image, _ = mne.viz.plot_topomap(bp_map, pos, mask=mask, axes=ax_topo, cmap='Reds',\n",
    "#                             vmin=np.min, vmax=np.max, show=False)\n",
    "#     divider = make_axes_locatable(ax_topo)\n",
    "\n",
    "#     # add axes for colorbar\n",
    "#     ax_colorbar = divider.append_axes('right', size='5%', pad=0.05)\n",
    "#     plt.colorbar(image, cax=ax_colorbar)\n",
    "# #     ax_topo.set_xlabel('Averaged baseline alpha bandpower OP-VD for {}'.format(group))\n",
    "    \n",
    "# #     ax_topo.set_xlabel('Averaged baseline alpha bandpower FA-VD for {}'.format(group))\n",
    "\n",
    "#     ax_topo.set_xlabel('Averaged baseline alpha bandpower OP-FA for {}'.format(group))\n",
    "    \n",
    "#     mne.viz.tight_layout(fig=fig)\n",
    "#     fig.subplots_adjust(bottom=.05)\n",
    "# #     plt.show()\n",
    "# #     fig.savefig('/home/gansheng.tan/process_mne/INSERM_EEG_Enrico_Proc/data_eeglab/full_epochs_data/statistic/OP-VD_alpha_baseline topoplot.png')\n",
    "# #     fig.savefig('/home/gansheng.tan/process_mne/INSERM_EEG_Enrico_Proc/data_eeglab/full_epochs_data/statistic/FA-VD_alpha_baseline topoplot'+'i_clu'+'.png')\n",
    "#     fig.savefig('/home/gansheng.tan/process_mne/INSERM_EEG_Enrico_Proc/data_eeglab/full_epochs_data/statistic/OP-FA_alpha_baseline topoplot'+'i_clu'+'.png')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
