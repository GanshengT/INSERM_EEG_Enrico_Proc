{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T16:28:38.455672Z",
     "start_time": "2018-05-31T16:28:38.029386Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adorb\\WinPython-64bit-3.6.3.0Qt5\\python-3.6.3.amd64\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "from header import *\n",
    "from mne.stats import spatio_temporal_cluster_1samp_test, spatio_temporal_cluster_test, permutation_cluster_1samp_test, permutation_cluster_test, summarize_clusters_stc\n",
    "from scipy.stats.distributions import f,t\n",
    "from tqdm import tqdm\n",
    "import xarray as xr\n",
    "#warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T16:28:49.581843Z",
     "start_time": "2018-05-31T16:28:49.549387Z"
    }
   },
   "outputs": [],
   "source": [
    "t0 = time.perf_counter()\n",
    "task = 'SMEG' #'MIMOSA'\n",
    "states = ['RS','FA','OM']\n",
    "subjects = get_subjlist(task)#, include_all=True)\n",
    "\n",
    "no_blk2 = ['002', '004', '007', '016']\n",
    "no_mri = ['019', '021']\n",
    "reject = ['002', '004', '010', '011']\n",
    "for sub in no_mri + reject:\n",
    "    if sub in subjects:\n",
    "        subjects.remove(sub)\n",
    "\n",
    "subjects.sort()\n",
    "experts = []\n",
    "novices = []\n",
    "experts_i = []\n",
    "novices_i = []\n",
    "for s,sub in enumerate(subjects):\n",
    "    if expertise(sub) == 'N':\n",
    "        novices.append(sub)\n",
    "        novices_i.append(s)\n",
    "    if expertise(sub) == 'E':\n",
    "        experts.append(sub)\n",
    "        experts_i.append(s)\n",
    "\n",
    "clu = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adorb\\WinPython-64bit-3.6.3.0Qt5\\python-3.6.3.amd64\\lib\\site-packages\\xarray\\core\\computation.py:561: RuntimeWarning: divide by zero encountered in log10\n",
      "  result_data = func(*input_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray (state: 5, subject: 55, freq: 601, chan: 275)>\n",
      "array([[[[-0.742847, ..., -1.14245 ],\n",
      "         ...,\n",
      "         [-0.91831 , ..., -1.018539]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.27061 , ..., -1.290707],\n",
      "         ...,\n",
      "         [-1.028558, ..., -1.510826]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[      nan, ...,       nan],\n",
      "         ...,\n",
      "         [      nan, ...,       nan]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.388662, ..., -1.536819],\n",
      "         ...,\n",
      "         [-1.55772 , ..., -1.396532]]]])\n",
      "Coordinates:\n",
      "  * subject  (subject) object '007' '012' '014' '016' ... '105' '108' '109'\n",
      "  * chan     (chan) object 'MLC11' 'MLC12' 'MLC13' ... 'MZO02' 'MZO03' 'MZP01'\n",
      "  * state    (state) object 'RS1' 'FA1' 'FA2' 'OM1' 'OM2'\n",
      "  * freq     (freq) float64 0.0 0.5 1.0 1.5 2.0 ... 298.5 299.0 299.5 300.0\n"
     ]
    }
   ],
   "source": [
    "PSD = xr.open_dataarray(op.join(Analysis_path, task, 'meg', 'Alpha', 'PSD.nc'))\n",
    "PSD.load()\n",
    "PSD = PSD.transpose('state', 'subject', 'freq', 'chan')\n",
    "PSD_norm = np.log10(PSD) #log transform\n",
    "PSD_norm = (PSD_norm - PSD_norm.mean('chan'))/PSD_norm.std('chan') #spatial normalisation\n",
    "#PSD_norm = PSD/PSD.sum(['freq', 'chan'])\n",
    "print(PSD_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray (state: 3, subject: 55, freq: 601, chan: 275)>\n",
      "array([[[[-0.742847, ..., -1.14245 ],\n",
      "         ...,\n",
      "         [-0.91831 , ..., -1.018539]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.27061 , ..., -1.290707],\n",
      "         ...,\n",
      "         [-1.028558, ..., -1.510826]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[-1.620123, ..., -0.833436],\n",
      "         ...,\n",
      "         [-1.227106, ..., -1.297156]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.515533, ..., -1.564723],\n",
      "         ...,\n",
      "         [-1.312812, ..., -1.248828]]]])\n",
      "Coordinates:\n",
      "  * state    (state) <U2 'RS' 'FA' 'OM'\n",
      "  * subject  (subject) object '007' '012' '014' '016' ... '105' '108' '109'\n",
      "  * freq     (freq) float64 0.0 0.5 1.0 1.5 2.0 ... 298.5 299.0 299.5 300.0\n",
      "  * chan     (chan) object 'MLC11' 'MLC12' 'MLC13' ... 'MZO02' 'MZO03' 'MZP01'\n"
     ]
    }
   ],
   "source": [
    "PSD_ave = np.empty((len(states), *PSD_norm.shape[1:]))\n",
    "for s,state in enumerate(states):\n",
    "    PSD_ave[s] = PSD_norm.loc[fnmatch.filter(PSD_norm.state.values, state+'*')].mean('state').values\n",
    "coords = {dim: PSD_norm.coords[dim].values for dim in PSD_norm.dims}\n",
    "coords.update({'state': states})\n",
    "PSD_ave = xr.DataArray(PSD_ave, dims=PSD_norm.dims, coords=coords)\n",
    "print(PSD_ave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensor_perm_test(X1, X2, stat_file, test_key, freqs, sensors, mode='a', p_threshold=0.01, connectivity=None, paired=False, fif_significance=0.05):\n",
    "    \"\"\"\n",
    "    If paired, test X1-X2.\n",
    "    A summary Evoked of the stats is saved if there is a significant cluster (p-value < fif_significance).\n",
    "    (Time is replaced by freqs.)\n",
    "    Saving can be forced by setting fif_significance to 1, or disabled by setting it to 0.\n",
    "    Input: arrays of shape (subjects, freq, space)\n",
    "    \"\"\"\n",
    "    os.makedirs(op.dirname(stat_file), exist_ok=True)\n",
    "    evoked_file = op.splitext(stat_file)[0] + '_' + test_key + '_stat-ave.fif'\n",
    "    \n",
    "    if not isinstance(X2, (np.ndarray, xr.DataArray, list)):\n",
    "        X2 = np.zeros(X1.shape)\n",
    "    \n",
    "    if paired:\n",
    "        X = X1 - X2\n",
    "        t_threshold = -t.ppf(p_threshold / 2, X.shape[0] - 1)\n",
    "        T_obs, clusters, cluster_pv, H0 = clu_all = spatio_temporal_cluster_1samp_test(X, connectivity=connectivity, threshold=t_threshold, n_jobs=4)\n",
    "    else:\n",
    "        f_threshold = f.ppf(1 - p_threshold / 2, X1.shape[0] - 1, X2.shape[0] - 1)\n",
    "        T_obs, clusters, cluster_pv, H0 = clu_all = spatio_temporal_cluster_test([X1,X2], connectivity=connectivity, threshold=f_threshold, n_jobs=4)\n",
    "    \n",
    "    p_val = np.ones_like(T_obs)\n",
    "    clu_inds = np.zeros_like(T_obs)\n",
    "    \n",
    "    info_file = op.join(Analysis_path, 'MEG', 'meta', 'mag-info.fif')\n",
    "    if op.isfile(info_file):\n",
    "        info = mne.io.read_info(info_file)\n",
    "        info['sfreq'] = 1 / (freqs[1] - freqs[0])\n",
    "    else:\n",
    "        info = mne.create_info(sensors, 1 / (freqs[1] - freqs[0]), 'mag')\n",
    "    \n",
    "    evokeds = []\n",
    "    for c,clu in enumerate(clusters):\n",
    "        p_val[clu] = cluster_pv[c]\n",
    "        clu_inds[clu] = c+1\n",
    "        if np.any(cluster_pv[c] <= fif_significance):\n",
    "            data = np.full_like(T_obs, 0)#np.nan)\n",
    "            data[clu] = T_obs[clu]\n",
    "            #mne.write_evokeds(evoked_file, mne.EvokedArray(data.T, info, freqs[0], 'cluster_{}'.format(c+1)))\n",
    "            evokeds.append(mne.EvokedArray(data.T, info, freqs[0], 'cluster_{}'.format(c+1)))\n",
    "    \n",
    "    if np.any(p_val <= fif_significance):\n",
    "        evokeds.append(mne.EvokedArray(np.where(p_val <= fif_significance, T_obs, 0).T, info, freqs[0], 'all_clusters'))\n",
    "        mne.write_evokeds(evoked_file, evokeds)\n",
    "    \n",
    "    stats = xr.DataArray(np.zeros((3, *T_obs.shape)), dims=['data', 'freq', 'sensor'], coords={'data':['T_stat', 'p_val', 'clu_inds'], 'freq':freqs, 'sensor':sensors})\n",
    "    stats.loc['T_stat'] = T_obs\n",
    "    stats.loc['p_val'] = p_val\n",
    "    stats.loc['clu_inds'] = clu_inds\n",
    "    \n",
    "    stats.to_netcdf(path=stat_file, group=test_key, mode=mode if op.isfile(stat_file) else 'w')\n",
    "    return clu_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmin = .5 #PSD_norm.freq.values[0]\n",
    "fmax = 100 #PSD_norm.freq.values[-1]\n",
    "stat_path = op.join(Analysis_path, task, 'meg', 'Stats', 'PSD')\n",
    "os.makedirs(stat_path, exist_ok=True)\n",
    "stat_file = op.join(stat_path, '{}-{}Hz.nc'.format(fmin, fmax))\n",
    "paired_tests = {'FA_vs_RS':('FA', 'RS', subjects), 'OM_vs_RS':('OM', 'RS', subjects),\n",
    "         'FA_vs_OM':('FA', 'OM', subjects), 'FA_vs_RS+E':('FA', 'RS', experts),\n",
    "         'OM_vs_RS+E':('OM', 'RS', experts), 'FA_vs_OM+E':('FA', 'OM', experts),\n",
    "         'FA_vs_RS+N':('FA', 'RS', novices), 'OM_vs_RS+N':('OM', 'RS', novices),\n",
    "         'FA_vs_OM+N':('FA', 'OM', novices)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FA_vs_RS\n",
      "stat_fun(H1): min=-7.282988 max=9.016923\n",
      "Running initial clustering\n",
      "Found 1032 clusters\n",
      "Permuting 1023 times...\n",
      "[                                                            ]   0.00%  |   \n",
      "Computing cluster p-values\n",
      "Done.\n",
      "Isotrak not found\n",
      "OM_vs_RS\n",
      "stat_fun(H1): min=-8.455271 max=8.887150\n",
      "Running initial clustering\n",
      "Found 923 clusters\n",
      "Permuting 1023 times...\n",
      "[                                                            ]   0.00%  |   \n",
      "Computing cluster p-values\n",
      "Done.\n",
      "Isotrak not found\n",
      "FA_vs_OM\n",
      "stat_fun(H1): min=-4.702927 max=4.402146\n",
      "Running initial clustering\n",
      "Found 425 clusters\n",
      "Permuting 1023 times...\n",
      "[                                                            ]   0.00%  |   \n",
      "Computing cluster p-values\n",
      "Done.\n",
      "Isotrak not found\n",
      "FA_vs_RS+E\n",
      "stat_fun(H1): min=-10.103457 max=9.145466\n",
      "Running initial clustering\n",
      "Found 1042 clusters\n",
      "Permuting 1023 times...\n",
      "[                                                            ]   0.00%  |   \n",
      "Computing cluster p-values\n",
      "Done.\n",
      "Isotrak not found\n",
      "OM_vs_RS+E\n",
      "stat_fun(H1): min=-9.290717 max=7.394066\n",
      "Running initial clustering\n",
      "Found 1020 clusters\n",
      "Permuting 1023 times...\n",
      "[                                                            ]   0.00%  |   \n",
      "Computing cluster p-values\n",
      "Done.\n",
      "Isotrak not found\n",
      "FA_vs_OM+E\n",
      "stat_fun(H1): min=-5.383812 max=5.451951\n",
      "Running initial clustering\n",
      "Found 342 clusters\n",
      "Permuting 1023 times...\n",
      "[                                                            ]   0.00%  |   \n",
      "Computing cluster p-values\n",
      "Done.\n",
      "Isotrak not found\n",
      "FA_vs_RS+N\n",
      "stat_fun(H1): min=-6.636815 max=6.882460\n",
      "Running initial clustering\n",
      "Found 1094 clusters\n",
      "Permuting 1023 times...\n",
      "[                                                            ]   0.00%  |   \n",
      "Computing cluster p-values\n",
      "Done.\n",
      "Isotrak not found\n",
      "OM_vs_RS+N\n",
      "stat_fun(H1): min=-7.093337 max=8.180739\n",
      "Running initial clustering\n",
      "Found 1029 clusters\n",
      "Permuting 1023 times...\n",
      "[                                                            ]   0.00%  |   \n",
      "Computing cluster p-values\n",
      "Done.\n",
      "Isotrak not found\n",
      "FA_vs_OM+N\n",
      "stat_fun(H1): min=-4.107134 max=4.402586\n",
      "Running initial clustering\n",
      "Found 276 clusters\n",
      "Permuting 1023 times...\n",
      "[                                                            ]   0.00%  |   \n",
      "Computing cluster p-values\n",
      "Done.\n",
      "Isotrak not found\n"
     ]
    }
   ],
   "source": [
    "for key,val in paired_tests.items():\n",
    "    logger.info(key)\n",
    "    clu[key] = sensor_perm_test(PSD_ave.loc[val[0],val[2],fmin:fmax].values, PSD_ave.loc[val[1],val[2],fmin:fmax].values, stat_file=stat_file, test_key=key, freqs=PSD_ave.loc[:,:,fmin:fmax].freq.values, sensors=PSD_ave.chan.values.tolist(), paired=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expertise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmin = .5 #PSD_norm.freq.values[0]\n",
    "fmax = 100 #PSD_norm.freq.values[-1]\n",
    "stat_path = op.join(Analysis_path, task, 'meg', 'Stats', 'PSD')\n",
    "os.makedirs(stat_path, exist_ok=True)\n",
    "stat_file = op.join(stat_path, '{}-{}Hz.nc'.format(fmin, fmax))\n",
    "exp_tests = {'N_vs_E+RS': 'RS', 'N_vs_E+FA': 'FA', 'N_vs_E+OM': 'OM'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_vs_E+RS\n",
      "stat_fun(H1): min=0.000000 max=18.011232\n",
      "Running initial clustering\n",
      "Found 1276 clusters\n",
      "Permuting 1023 times...\n",
      "[                                                            ]   0.00%  |   \n",
      "Computing cluster p-values\n",
      "Done.\n",
      "Isotrak not found\n",
      "N_vs_E+FA\n",
      "stat_fun(H1): min=0.000000 max=15.438451\n",
      "Running initial clustering\n",
      "Found 1052 clusters\n",
      "Permuting 1023 times...\n",
      "[                                                            ]   0.00%  |   \n",
      "Computing cluster p-values\n",
      "Done.\n",
      "Isotrak not found\n",
      "N_vs_E+OM\n",
      "stat_fun(H1): min=0.000000 max=15.656503\n",
      "Running initial clustering\n",
      "Found 674 clusters\n",
      "Permuting 1023 times...\n",
      "[                                                            ]   0.00%  |   \n",
      "Computing cluster p-values\n",
      "Done.\n",
      "Isotrak not found\n"
     ]
    }
   ],
   "source": [
    "for key,val in exp_tests.items():\n",
    "    logger.info(key)\n",
    "    clu[key] = sensor_perm_test(PSD_ave.loc[val,novices,fmin:fmax].values, PSD_ave.loc[val,experts,fmin:fmax].values, stat_file=stat_file, test_key=key, freqs=PSD_ave.loc[:,:,fmin:fmax].freq.values, sensors=PSD_ave.chan.values.tolist(), paired=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmin = .5 #PSD_norm.freq.values[0]\n",
    "fmax = 100 #PSD_norm.freq.values[-1]\n",
    "stat_path = op.join(Analysis_path, task, 'meg', 'Stats', 'PSD')\n",
    "os.makedirs(stat_path, exist_ok=True)\n",
    "stat_file = op.join(stat_path, '{}-{}Hz.nc'.format(fmin, fmax))\n",
    "inter_tests = {'N_vs_E+OM-RS': ('OM', 'RS'), 'N_vs_E+FA-RS': ('FA', 'RS'), 'N_vs_E+FA-OM': ('FA', 'OM')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_vs_E+OM-RS\n",
      "stat_fun(H1): min=0.000000 max=25.849906\n",
      "Running initial clustering\n",
      "Found 1870 clusters\n",
      "Permuting 1023 times...\n",
      "[                                                            ]   0.00%  |   \n",
      "Computing cluster p-values\n",
      "Done.\n",
      "Isotrak not found\n",
      "N_vs_E+FA-RS\n",
      "stat_fun(H1): min=0.000000 max=20.288456\n",
      "Running initial clustering\n",
      "Found 1814 clusters\n",
      "Permuting 1023 times...\n",
      "[                                                            ]   0.00%  |   \n",
      "Computing cluster p-values\n",
      "Done.\n",
      "Isotrak not found\n",
      "N_vs_E+FA-OM\n",
      "stat_fun(H1): min=0.000000 max=17.447795\n",
      "Running initial clustering\n",
      "Found 1858 clusters\n",
      "Permuting 1023 times...\n",
      "[                                                            ]   0.00%  |   \n",
      "Computing cluster p-values\n",
      "Done.\n",
      "Isotrak not found\n"
     ]
    }
   ],
   "source": [
    "for key,val in inter_tests.items():\n",
    "    logger.info(key)\n",
    "    clu[key] = sensor_perm_test(PSD_ave.loc[val[0],novices,fmin:fmax].values - PSD_ave.loc[val[1],novices,fmin:fmax].values, PSD_ave.loc[val[0],experts,fmin:fmax].values - PSD_ave.loc[val[1],experts,fmin:fmax].values, stat_file=stat_file, test_key=key, freqs=PSD_ave.loc[:,:,fmin:fmax].freq.values, sensors=PSD_ave.chan.values.tolist(), paired=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
